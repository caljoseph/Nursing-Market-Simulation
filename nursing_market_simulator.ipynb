{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How Many Agencies Does Covr Have Access To?\n",
        "\n",
        "## Purpose\n",
        "This notebook estimates the number of agencies that Covr could potentially connect with through its nursing facility clients.\n",
        "\n",
        "## Required External Files\n",
        "1. `covr_addresses.csv`\n",
        "2. `all_nursing_home_coordinates.csv`\n",
        "\n",
        "**Note:** These files may be updated as needed.\n",
        "\n",
        "## Coordinate Generation\n",
        "If `covr_coordinates.csv` doesn't exist in the parent folder:\n",
        "- You will be prompted for a Google Maps API key\n",
        "- The file will be automatically generated for you\n",
        "\n",
        "**Important:** If you update `covr_addresses.csv`, you must:\n",
        "1. Delete `covr_coordinates.csv`\n",
        "2. Run the notebook again to regenerate coordinates for your new address list\n"
      ],
      "metadata": {
        "id": "pXC1ZmS2Go11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "cl3nAJtPXECG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5pdbVvsOG_C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tqdm\n",
        "from scipy.stats import norm\n",
        "from tqdm import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from geopy.distance import geodesic\n",
        "import math\n",
        "from scipy.stats import gaussian_kde\n",
        "from scipy.spatial import cKDTree\n",
        "import multiprocessing as mp\n",
        "\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from google.colab import drive\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "from collections import Counter\n",
        "from functools import partial\n",
        "import pandas as pd\n",
        "from matplotlib.lines import Line2D\n",
        "try:\n",
        "  from mpl_toolkits.basemap import Basemap\n",
        "except:\n",
        "  !pip install basemap\n",
        "  from mpl_toolkits.basemap import Basemap\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters\n",
        "\n"
      ],
      "metadata": {
        "id": "wUWrGLY5X6vh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcdzN_DfZetD"
      },
      "outputs": [],
      "source": [
        "### PARAMETERS ###\n",
        "\n",
        "# MARKET ASSUMPTIONS\n",
        "num_agencies = 8000 # number of agencies in the market\n",
        "mean_agencies = 3 # mean number of agencies per facility\n",
        "std_dev_agencies = 1 # standard deviation of agencies per facility\n",
        "proportion_covr_facilities_use_agency = .75 # how many of covr's facilities use agency?\n",
        "\n",
        "# FACILITY BEHAVIOR ASSUMPTIONS\n",
        "distance_cutoff = 200  # Miles beyond which a facility will never connect with an agency\n",
        "distance_midpoint = 70  # Distance (in miles) at which probability of a facility considering an agency is 0.5\n",
        "steepness = 0.3  # Controls how quickly probability of connecting with an agency drops off with distance\n",
        "\n",
        "# CONFIDENCE SIMULATION HELPER VALUES\n",
        "confidence = .95  # confidence interval\n",
        "samples = 100  # number of simulations to perform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u77qwzILU8Pd"
      },
      "outputs": [],
      "source": [
        "# Google Drive Setup\n",
        "drive.mount('/drive', force_remount=True)\n",
        "directory = '/drive/My Drive/Covr Agency Simulator/'\n",
        "\n",
        "covr_addresses_path = os.path.join(directory, 'covr_addresses.csv')\n",
        "covr_coordinates_path = os.path.join(directory, 'covr_coordinates.csv')\n",
        "all_nursing_home_coordinates = pd.read_csv(os.path.join(directory, 'all_nursing_home_coordinates.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate New Covr Coordinates"
      ],
      "metadata": {
        "id": "Mj-ZXkxJYmd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_for_api_key():\n",
        "    return input(\"Please enter your Google Maps API key: \")\n",
        "\n",
        "def address_to_geocode(address, api_key):\n",
        "    url = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
        "    params = {'address': address, 'key': api_key}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if data['status'] == 'OK':\n",
        "            location = data['results'][0]['geometry']['location']\n",
        "            return location['lat'], location['lng']\n",
        "        else:\n",
        "            print(f\"Geocoding failed for address: {address}. Status: {data['status']}\")\n",
        "            if 'error_message' in data:\n",
        "                print(f\"Error message: {data['error_message']}\")\n",
        "            return None, None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed for address: {address}. Error: {e}\")\n",
        "        return None, None\n",
        "    # finally:\n",
        "        # time.sleep(0.1)\n",
        "\n",
        "def process_csv(input_file, api_key):\n",
        "    df = pd.read_csv(input_file)\n",
        "    address_column = df.columns[0]\n",
        "\n",
        "    geocoded_data = []\n",
        "    skipped_addresses = []\n",
        "\n",
        "    def geocode_with_retry(address, max_retries=3):\n",
        "        for attempt in range(max_retries):\n",
        "            lat, lng = address_to_geocode(address, api_key)\n",
        "            if lat is not None and lng is not None:\n",
        "                return lat, lng\n",
        "            time.sleep(1)\n",
        "        return None, None\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        address = row[address_column]\n",
        "        lat, lng = geocode_with_retry(address)\n",
        "        if lat is not None and lng is not None:\n",
        "            geocoded_data.append({'Address': address, 'Latitude': lat, 'Longitude': lng})\n",
        "        else:\n",
        "            skipped_addresses.append(address)\n",
        "\n",
        "    # Create a new DataFrame with only successfully geocoded addresses\n",
        "    result_df = pd.DataFrame(geocoded_data)\n",
        "\n",
        "    # Log skipped addresses\n",
        "    if skipped_addresses:\n",
        "        print(\"The following addresses were skipped:\")\n",
        "        for addr in skipped_addresses:\n",
        "            print(addr)\n",
        "\n",
        "        # Optionally, save skipped addresses to a file\n",
        "        with open('skipped_addresses.txt', 'w') as f:\n",
        "            f.write('\\n'.join(skipped_addresses))\n",
        "        print(\"Skipped addresses have been saved to 'skipped_addresses.txt'\")\n",
        "\n",
        "    return result_df\n",
        "\n",
        "# Check if the geocoded file already exists\n",
        "if os.path.exists(covr_coordinates_path):\n",
        "    print(f\"The file {covr_coordinates_path} already exists.\")\n",
        "    covr_coordinates = pd.read_csv(covr_coordinates_path)\n",
        "    display(covr_coordinates)\n",
        "else:\n",
        "    print(f\"The file {covr_coordinates_path} does not exist. Processing addresses...\")\n",
        "\n",
        "    # Ensure the input file exists\n",
        "    if not os.path.exists(covr_addresses_path):\n",
        "        raise FileNotFoundError(f\"The input file {covr_addresses_path} does not exist.\")\n",
        "\n",
        "    # Prompt for API key\n",
        "    api_key = prompt_for_api_key()\n",
        "\n",
        "    # Run the csv through the google maps API and return a DF\n",
        "    covr_coordinates = process_csv(covr_addresses_path, api_key)\n",
        "    display(covr_coordinates)\n",
        "\n",
        "    # Save the result to the output CSV file\n",
        "    covr_coordinates.to_csv(covr_coordinates_path, index=False)\n",
        "    print(f\"Results saved to {covr_coordinates_path}\")"
      ],
      "metadata": {
        "id": "MpKYkhgvnfax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Simulation"
      ],
      "metadata": {
        "id": "LYEQ5e6lZgwW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4YJD5w5lqHp"
      },
      "outputs": [],
      "source": [
        "# This function generates a dataframe of simulated agencies based on the distribution of the nursing facility market in all_nursing_home_coordinates\n",
        "\n",
        "class Agency:\n",
        "    def __init__(self, id, latitude, longitude):\n",
        "        self.location = (latitude, longitude)\n",
        "        self.id = id\n",
        "\n",
        "def simulate_agency_coordinates(all_nursing_home_coordinates, covr_coordinates, num_agencies, max_offset_miles):\n",
        "    # Extract coordinates\n",
        "    coords = all_nursing_home_coordinates[['LONGITUDE', 'LATITUDE']].values\n",
        "\n",
        "    # Randomly sample with replacement\n",
        "    sampled_indices = np.random.choice(len(coords), num_agencies, replace=True)\n",
        "    sampled_points = coords[sampled_indices]\n",
        "\n",
        "    # Add small random offset\n",
        "    offset_lat = np.random.uniform(-max_offset_miles/69, max_offset_miles/69, num_agencies)\n",
        "    offset_lon = np.random.uniform(-max_offset_miles/54.6, max_offset_miles/54.6, num_agencies)\n",
        "\n",
        "    simulated_points = sampled_points + np.column_stack((offset_lon, offset_lat))\n",
        "\n",
        "    # Create a DataFrame with the simulated coordinates\n",
        "    simulated_agencies = pd.DataFrame({\n",
        "        'Longitude': simulated_points[:, 0],\n",
        "        'Latitude': simulated_points[:, 1]\n",
        "    })\n",
        "\n",
        "    # Visualize the results\n",
        "    plt.figure(figsize=(10, 7))\n",
        "\n",
        "    # Create the Basemap\n",
        "    m = Basemap(llcrnrlon=-125, llcrnrlat=23, urcrnrlon=-65, urcrnrlat=50,\n",
        "                projection='lcc', lat_1=33, lat_2=45, lon_0=-95, resolution='l')\n",
        "\n",
        "    # Draw map features\n",
        "    m.drawcoastlines(linewidth=0.5)\n",
        "    m.drawcountries(linewidth=0.5)\n",
        "    m.drawstates(linewidth=0.3)\n",
        "    m.fillcontinents(color='#FFEECC', lake_color='#99B3CC', alpha=0.3)\n",
        "    m.drawmapboundary(fill_color='#99B3CC')\n",
        "\n",
        "    # Convert lat/lon to map coordinates\n",
        "    x, y = m(coords[:, 0], coords[:, 1])\n",
        "    sim_x, sim_y = m(simulated_agencies['Longitude'], simulated_agencies['Latitude'])\n",
        "    covr_x, covr_y = m(covr_coordinates['Longitude'], covr_coordinates['Latitude'])\n",
        "\n",
        "    # Plot the data\n",
        "    m.scatter(x, y, alpha=0.4, s=.5, color='blue', zorder=3)\n",
        "    m.scatter(sim_x, sim_y, alpha=0.4, s=.5, color='green', zorder=4)\n",
        "    m.scatter(covr_x, covr_y, alpha=1, s=2, color='red', zorder=5)\n",
        "\n",
        "    # Create custom legend elements\n",
        "    legend_elements = [\n",
        "      Line2D([0], [0], marker='o', color='w', label='All Facilities',\n",
        "            markerfacecolor='blue', markersize=10),\n",
        "      Line2D([0], [0], marker='o', color='w', label='Simulated Agencies',\n",
        "            markerfacecolor='green', markersize=10),\n",
        "      Line2D([0], [0], marker='o', color='w', label='Covr facilities',\n",
        "            markerfacecolor='red', markersize=10)\n",
        "    ]\n",
        "\n",
        "    # Add the legend with custom elements\n",
        "    plt.legend(handles=legend_elements, loc='lower center', bbox_to_anchor=(0.5, -0.1), ncol=3)\n",
        "\n",
        "    plt.title(f'Distribution of Nursing Homes and Simulated Agencies (Max Offset: {max_offset_miles} miles)', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return simulated_agencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwPh_jLidVPq"
      },
      "outputs": [],
      "source": [
        "def calculate_distance(coord1, coord2):\n",
        "    \"\"\"Calculate distance between two coordinates in miles.\"\"\"\n",
        "    return geodesic(coord1, coord2).miles\n",
        "\n",
        "def calculate_weight(distance, midpoint=distance_midpoint, steepness=steepness):\n",
        "    \"\"\"Calculate how reasonable an agency is based on distance\"\"\"\n",
        "    # This calculation is a simple logistic function graphed below\n",
        "    return 1 / (1 + math.exp((distance - midpoint) / (midpoint * steepness)))\n",
        "\n",
        "def plot_distance_weight_curve(midpoint=distance_midpoint, steepness=steepness, max_distance=distance_cutoff):\n",
        "    distances = np.linspace(0, max_distance, 1000)\n",
        "    weights = [calculate_weight(d, midpoint, steepness) for d in distances]\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(distances, weights)\n",
        "    plt.title(f'Agency Distance Dropoff Curve (Midpoint: {midpoint}, Steepness: {steepness})')\n",
        "    plt.xlabel('Distance (miles)')\n",
        "    plt.ylabel('Weight')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCGVv1MvZIT8"
      },
      "outputs": [],
      "source": [
        "class Facility:\n",
        "    def __init__(self, latitude, longitude):\n",
        "        self.location = (latitude, longitude)\n",
        "        self.connected_agencies = []\n",
        "        self.reasonable_agencies = []\n",
        "\n",
        "    def connect_with_agency(self, agency):\n",
        "        if not isinstance(agency, Agency):\n",
        "            raise ValueError(\"Agency must be of type Agency\")\n",
        "\n",
        "        # Check if the agency is already connected\n",
        "        if any(connected_agency.id == agency.id for connected_agency in self.connected_agencies):\n",
        "            return False\n",
        "\n",
        "        # If it's not already connected, add it to the list\n",
        "        self.connected_agencies.append(agency)\n",
        "        return True\n",
        "\n",
        "    def add_reasonable_agencies(self, all_agencies):\n",
        "      # We go through the list of all the agencies we generated\n",
        "      for agency in all_agencies:\n",
        "        # And if they are within our geography we add them to our list of reasonable agencies to choose from later\n",
        "        distance = calculate_distance(self.location, agency.location)\n",
        "        if distance <= distance_cutoff:\n",
        "          self.reasonable_agencies.append(agency)\n",
        "\n",
        "    def select_weighted_agency(self):\n",
        "        if not self.reasonable_agencies:\n",
        "            return None\n",
        "\n",
        "        # Filter out already connected agencies\n",
        "        available_agencies = [(agency, weight) for agency, weight in self.reasonable_agencies\n",
        "                              if agency not in self.connected_agencies]\n",
        "\n",
        "        if not available_agencies:\n",
        "            return None\n",
        "\n",
        "        agencies, weights = zip(*available_agencies)\n",
        "        total_weight = sum(weights)\n",
        "        normalized_weights = [w / total_weight for w in weights]\n",
        "\n",
        "        selected_agency = random.choices(agencies, weights=normalized_weights, k=1)[0]\n",
        "        return selected_agency\n",
        "\n",
        "    def remove_all_connected_agencies(self):\n",
        "        self.connected_agencies = []\n",
        "\n",
        "    def get_all_agencies(self):\n",
        "        return self.connected_agencies\n",
        "\n",
        "    def get_connected_agencies(self):\n",
        "        return self.connected_agencies\n",
        "    def get_reasonable_agencies(self):\n",
        "        return self.reasonable_agencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FY20s-9VZ33"
      },
      "outputs": [],
      "source": [
        "def process_facility(args):\n",
        "    facility, tree, all_agencies, distance_cutoff, distance_midpoint, steepness = args\n",
        "    distances, indices = tree.query(facility.location, k=len(all_agencies), distance_upper_bound=distance_cutoff)\n",
        "\n",
        "    facility.reasonable_agencies = []\n",
        "    for dist, idx in zip(distances, indices):\n",
        "        if idx < len(all_agencies):\n",
        "            agency = all_agencies[idx]\n",
        "            exact_distance = geodesic(facility.location, agency.location).miles\n",
        "            if exact_distance <= distance_cutoff:\n",
        "                weight = calculate_weight(exact_distance, distance_midpoint, steepness)\n",
        "                facility.reasonable_agencies.append((agency, weight))\n",
        "\n",
        "    return facility\n",
        "\n",
        "def optimize_facility_agency_matching(covr_coordinates, agencies, distance_cutoff=distance_cutoff, distance_midpoint=distance_midpoint, steepness=steepness, proportion_covr_facilities_use_agency=proportion_covr_facilities_use_agency):\n",
        "    print(\"Creating facilities...\")\n",
        "    all_facilities = [Facility(row['Latitude'], row['Longitude']) for _, row in tqdm(covr_coordinates.iterrows(), total=len(covr_coordinates))]\n",
        "\n",
        "    # Determine which facilities use agencies\n",
        "    num_facilities_use_agency = int(len(all_facilities) * proportion_covr_facilities_use_agency)\n",
        "    facilities_use_agency = np.random.choice(all_facilities, num_facilities_use_agency, replace=False)\n",
        "\n",
        "    print(f\"Number of facilities that use agencies: {num_facilities_use_agency}\")\n",
        "\n",
        "    print(\"Building KD-Tree for agencies...\")\n",
        "    agency_coords = np.array([[agency.location[0], agency.location[1]] for agency in tqdm(agencies)])\n",
        "    tree = cKDTree(agency_coords)\n",
        "\n",
        "    print(\"Matching facilities with agencies...\")\n",
        "    with mp.Pool(mp.cpu_count()) as pool:\n",
        "        args = [(facility, tree, agencies, distance_cutoff, distance_midpoint, steepness) for facility in facilities_use_agency]\n",
        "        facilities_with_agencies = list(tqdm(pool.imap(process_facility, args), total=len(facilities_use_agency)))\n",
        "\n",
        "    print(f\"Processed {len(facilities_with_agencies)} facilities that use agencies.\")\n",
        "    avg_num_reasonable_agencies = sum(len(f.get_reasonable_agencies()) for f in facilities_with_agencies) / len(facilities_with_agencies)\n",
        "    print(f\"Average number of reasonable agencies per facility (for facilities that use agencies): {avg_num_reasonable_agencies:.2f}\")\n",
        "\n",
        "    return facilities_with_agencies\n",
        "\n",
        "def run_facility_agency_connection(facilities, mean_agencies=mean_agencies, std_dev_agencies=std_dev_agencies):\n",
        "    total_connections = 0\n",
        "    all_connected_agencies = set()  # We'll use this to track all unique connected agencies\n",
        "\n",
        "    for facility in facilities:\n",
        "        facility.remove_all_connected_agencies()\n",
        "        num_agencies = max(0, int(np.random.normal(mean_agencies, std_dev_agencies)))\n",
        "        facility_connections = 0\n",
        "        for _ in range(num_agencies):\n",
        "            selected_agency = facility.select_weighted_agency()\n",
        "            if selected_agency:\n",
        "                if facility.connect_with_agency(selected_agency):\n",
        "                    facility_connections += 1\n",
        "            else:\n",
        "                break\n",
        "        total_connections += facility_connections\n",
        "\n",
        "        # After processing each facility, add its connected agencies to the overall set\n",
        "        all_connected_agencies.update(agency.id for agency in facility.get_connected_agencies())\n",
        "\n",
        "    # Now we have the correct count of unique agencies\n",
        "    unique_connected_agencies = len(all_connected_agencies)\n",
        "\n",
        "    return unique_connected_agencies, total_connections / len(facilities)\n",
        "\n",
        "def estimate_unique_agencies_with_confidence(facilities, mean_agencies=mean_agencies, std_dev_agencies=std_dev_agencies, confidence=confidence, n_iterations=samples):\n",
        "    unique_agency_counts = []\n",
        "    avg_agencies_per_facility_counts = []\n",
        "\n",
        "    for _ in range(n_iterations):\n",
        "        # This line was already correct, but our interpretation of it was wrong\n",
        "        unique_count, avg_count = run_facility_agency_connection(facilities, mean_agencies, std_dev_agencies)\n",
        "        unique_agency_counts.append(unique_count)\n",
        "        avg_agencies_per_facility_counts.append(avg_count)\n",
        "\n",
        "    unique_agency_counts = np.array(unique_agency_counts)\n",
        "    avg_agencies_per_facility_counts = np.array(avg_agencies_per_facility_counts)\n",
        "\n",
        "    # Calculate confidence intervals\n",
        "    ci_unique = stats.t.interval(confidence, len(unique_agency_counts) - 1,\n",
        "                                 loc=np.mean(unique_agency_counts),\n",
        "                                 scale=stats.sem(unique_agency_counts))\n",
        "\n",
        "    ci_avg = stats.t.interval(confidence, len(avg_agencies_per_facility_counts) - 1,\n",
        "                              loc=np.mean(avg_agencies_per_facility_counts),\n",
        "                              scale=stats.sem(avg_agencies_per_facility_counts))\n",
        "\n",
        "    # The fix is in correctly interpreting these results:\n",
        "    print(f\"Confidence interval is {confidence * 100}%\")\n",
        "    print(f\"Number of unique agencies Covr is connected to:\")\n",
        "    print(f\"  Min: {round(ci_unique[0])}\")\n",
        "    print(f\"  Max: {round(ci_unique[1])}\")\n",
        "    print(f\"  Mean: {round(np.mean(unique_agency_counts))}\")\n",
        "    print(f\"\\nAverage number of agencies per facility:\")\n",
        "    print(f\"  Min: {ci_avg[0]:.2f}\")\n",
        "    print(f\"  Max: {ci_avg[1]:.2f}\")\n",
        "    print(f\"  Mean: {np.mean(avg_agencies_per_facility_counts):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### MAIN\n",
        "\n",
        "# Create facilities\n",
        "all_facilities = []\n",
        "for index, row in covr_coordinates.iterrows():\n",
        "    facility = Facility(row['Latitude'], row['Longitude'])\n",
        "    facility.id = index\n",
        "    all_facilities.append(facility)\n",
        "\n",
        "# Create a list of agencies\n",
        "agencies = []\n",
        "simulated_agency_coordinates = simulate_agency_coordinates(all_nursing_home_coordinates, covr_coordinates, num_agencies=num_agencies, max_offset_miles=15)\n",
        "print(f\"Number of agencies generated: {len(simulated_agency_coordinates)}\")\n",
        "for index, row in simulated_agency_coordinates.iterrows():\n",
        "    agency = Agency(index, row['Latitude'], row['Longitude'])\n",
        "    agencies.append(agency)\n",
        "\n",
        "# Simulate facility-agency connections\n",
        "facilities_that_use_agency = []\n",
        "facilities_that_use_agency = optimize_facility_agency_matching(covr_coordinates, agencies)\n",
        "unique_agencies, avg_connections = run_facility_agency_connection(facilities_that_use_agency)\n",
        "print(f\"Number of unique agencies Covr is connected to: {unique_agencies}\")\n",
        "print(f\"Average number of agencies per facility: {avg_connections:.2f}\")\n",
        "estimate_unique_agencies_with_confidence(facilities_that_use_agency)"
      ],
      "metadata": {
        "id": "7jRL13_oBUAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimate_unique_agencies_with_confidence(facilities_that_use_agency)"
      ],
      "metadata": {
        "id": "4OW9wnGeunBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Results"
      ],
      "metadata": {
        "id": "PFBo9P-kY135"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5BkGcKOLUqt"
      },
      "outputs": [],
      "source": [
        "# Plots\n",
        "\n",
        "def plot_facility_agency_distribution(all_facilities, facilities_using_agencies):\n",
        "    # Create a dictionary of facilities using agencies for faster lookup\n",
        "    facilities_using_agencies_dict = {f.location: f for f in facilities_using_agencies}\n",
        "\n",
        "    # Create a list of agency counts for all facilities\n",
        "    agency_counts = [len(facilities_using_agencies_dict[f.location].connected_agencies)\n",
        "                     if f.location in facilities_using_agencies_dict else 0\n",
        "                     for f in all_facilities]\n",
        "\n",
        "    # Count the occurrences of each number of connections\n",
        "    count_distribution = Counter(agency_counts)\n",
        "\n",
        "    # Determine the maximum number of connections\n",
        "    max_connections = max(count_distribution.keys())\n",
        "\n",
        "    # Prepare data for plotting\n",
        "    x = range(max_connections + 1)  # 0 to max number of connections\n",
        "    y = [count_distribution[i] for i in x]\n",
        "\n",
        "    # Create the bar plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    bars = plt.bar(x, y)\n",
        "    plt.xlabel('Number of Agency Connections')\n",
        "    plt.ylabel('Number of Facilities')\n",
        "    plt.title('Distribution of Facilities by Number of Agency Connections')\n",
        "\n",
        "    # Color bars based on agency usage\n",
        "    for i, bar in enumerate(bars):\n",
        "        if i == 0:\n",
        "            bar.set_color('lightgray')\n",
        "        else:\n",
        "            bar.set_color('blue')\n",
        "\n",
        "    # Add value labels on top of each bar\n",
        "    for i, v in enumerate(y):\n",
        "        if v > 0:\n",
        "            plt.text(i, v, str(v), ha='center', va='bottom')\n",
        "\n",
        "    # Set x-axis to show only integer values\n",
        "    plt.xticks(x)\n",
        "\n",
        "    # Add a legend\n",
        "    plt.legend(['No Agencies', 'Uses Agencies'])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print summary statistics\n",
        "    facilities_using_agencies_count = sum(1 for count in agency_counts if count > 0)\n",
        "    print(f\"Total facilities: {len(all_facilities)}\")\n",
        "    print(f\"Facilities using agencies: {facilities_using_agencies_count} ({facilities_using_agencies_count/len(all_facilities)*100:.2f}%)\")\n",
        "    print(f\"Facilities not using agency: {len(all_facilities) - facilities_using_agencies_count}\")\n",
        "    if facilities_using_agencies_count > 0:\n",
        "        print(f\"Average agencies per facility (among those using agencies): {np.mean([count for count in agency_counts if count > 0]):.2f}\")\n",
        "    else:\n",
        "        print(\"No facilities are using agencies.\")\n",
        "\n",
        "def plot_agency_coverage(facilities, n_sample=5):\n",
        "    \"\"\"Plot the coverage area of a sample of facilities with agency weights determining opacity.\"\"\"\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    m = Basemap(llcrnrlon=-125, llcrnrlat=23, urcrnrlon=-65, urcrnrlat=50,\n",
        "                projection='lcc', lat_1=33, lat_2=45, lon_0=-95, resolution='l')\n",
        "\n",
        "    m.drawcoastlines(linewidth=0.5)\n",
        "    m.drawcountries(linewidth=0.5)\n",
        "    m.drawstates(linewidth=0.3)\n",
        "    m.fillcontinents(color='#FFEECC', lake_color='#99B3CC', alpha=0.3)\n",
        "    m.drawmapboundary(fill_color='#99B3CC')\n",
        "\n",
        "    colors = plt.cm.rainbow(np.linspace(0, 1, n_sample))\n",
        "\n",
        "    for facility, color in zip(np.random.choice(facilities, n_sample, replace=False), colors):\n",
        "        fac_x, fac_y = m(facility.location[1], facility.location[0])\n",
        "        m.scatter(fac_x, fac_y, color=color, s=100, label=f'Facility at {facility.location}', zorder=5)\n",
        "\n",
        "        # Normalize weights for this facility\n",
        "        weights = [weight for _, weight in facility.reasonable_agencies]\n",
        "        max_weight = max(weights)\n",
        "        min_weight = min(weights)\n",
        "        weight_range = max_weight - min_weight\n",
        "\n",
        "        for agency, weight in facility.reasonable_agencies:\n",
        "            agency_x, agency_y = m(agency.location[1], agency.location[0])\n",
        "\n",
        "            # Normalize the weight to determine opacity\n",
        "            if weight_range > 0:\n",
        "                opacity = 0.1 + 0.8 * (weight - min_weight) / weight_range\n",
        "            else:\n",
        "                opacity = 0.5  # Default opacity if all weights are the same\n",
        "\n",
        "            m.scatter(agency_x, agency_y, color=color, alpha=opacity, s=20, zorder=4)\n",
        "            m.plot([fac_x, agency_x], [fac_y, agency_y], color=color, alpha=opacity*0.5, linewidth=1, zorder=3)\n",
        "\n",
        "    plt.legend(loc='lower center', bbox_to_anchor=(0.5, -0.1), ncol=3)\n",
        "    plt.title('A Few Facilities and Their Reasonable Agencies', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_facility_agency_distribution(all_facilities, facilities_that_use_agency)\n",
        "plot_distance_weight_curve()\n",
        "plot_agency_coverage(facilities_that_use_agency)"
      ],
      "metadata": {
        "id": "Xws_aQHsY5n-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}